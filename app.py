from datetime import datetime

from st_pages import show_pages_from_config

from services.service_db import insert_question_answer
from services.service_google import translate
from services.service_openai import extract_query
from services.service_openai import generate_next_questions, generate_advanced_analytics, generate_main_ideas
from services.service_openai import get_embedding, get_streaming_response, generate_conclusion
from services.service_pinecone import search_fnguide, search_seeking_alpha_summary, search_seeking_alpha_content, \
    search_investment_bank
from services.service_search import search_news
from utils.streamlit_util import *

show_pages_from_config()
set_page_config()
write_common_style()
write_common_session_state()


def generate_prompt(instruct: str, question: str, news: List[dict]) -> str:
    news_text = ""
    for i, content in enumerate(news):
        news_text += f"""
title: {content["title"]}  
url: {content["url"]}  
related_paragraph: {content["related_paragraph"]}  
"""
    prompt = f"""
{instruct}
--- 
today: {datetime.now().strftime("%Y-%m-%d")}  
question: {question}  
"""
    if news:
        prompt += f"news\n{news_text}"
    prompt += "---"
    return prompt.strip()


def generate_analytics_prompt(instruct: str, paragraph: str, related_reports: List[dict]) -> str:
    report_text = ""
    for i, content in enumerate(report_text):
        domestic_metadata = content["metadata"]
        report_text += f"""
title: {domestic_metadata["title"]}  
content: {domestic_metadata["content"]}  
"""
    prompt = f"""
{instruct}
--- 
today: {datetime.now().strftime("%Y-%m-%d")}  
paragraph: {paragraph}  
"""
    if related_reports:
        prompt += f"analytics reports\n{report_text}"
    prompt += "---"
    return prompt.strip()


def get_domestic_reports(question_range: str, question_embedding: List[float]) -> List[dict]:
    domestic_report_list = []
    if question_range == "ì „ì²´" or question_range == "êµ­ë‚´":
        with st.spinner("êµ­ë‚´ ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ê²€ìƒ‰ ì¤‘..."):
            fnguide_report_list = search_fnguide(
                question_embedding,
                top_k=3,
            )
            domestic_report_list.extend(fnguide_report_list)
    return domestic_report_list


def get_oversea_reports(question_range: str, question_embedding: List[float]) -> List[dict]:
    oversea_report_list = []
    if question_range == "ì „ì²´" or question_range == "í•´ì™¸":
        with st.spinner("í•´ì™¸ ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ê²€ìƒ‰ ì¤‘..."):
            seeking_alpha_summary_list = search_seeking_alpha_summary(question_embedding, top_k=5)
            if seeking_alpha_summary_list:
                oversea_report_ids = [x["metadata"]["id"] for x in seeking_alpha_summary_list]
                seeking_alpha_content_list = search_seeking_alpha_content(question_embedding, oversea_report_ids, top_k=3)
                oversea_report_list.extend(seeking_alpha_content_list)
            investment_bank_list = search_investment_bank(question_embedding, top_k=3)
            oversea_report_list.extend(investment_bank_list)
    oversea_report_list = sorted(oversea_report_list, key=lambda x: x["score"], reverse=True)[:3]
    return oversea_report_list


def search_related_news(
        question_range: str,
        kor_query: str,
        kor_question_embedding: List[float],
        eng_query: str,
        eng_question_embedding: List[float]
) -> List[dict]:
    related_news = []
    if question_range == "êµ­ë‚´" or question_range == "ì „ì²´":
        with st.spinner("êµ­ë‚´ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘..."):
            domestic_news = search_news(kor_query, kor_question_embedding, is_domestic=True)
            related_news.extend(domestic_news)
    if question_range == "í•´ì™¸" or question_range == "ì „ì²´":
        with st.spinner("í•´ì™¸ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘..."):
            oversea_news = search_news(eng_query, eng_question_embedding, is_domestic=False)
            related_news.extend(oversea_news)
    related_news = sorted(related_news, key=lambda x: x["similarity"], reverse=True)[:3]
    return related_news


def search_related_reports(
        question_range: str,
        answer_embedding: List[float],
) -> List[dict]:
    domestic_report_list = get_domestic_reports(question_range, answer_embedding)
    oversea_report_list = get_oversea_reports(question_range, answer_embedding)
    related_reports = domestic_report_list + oversea_report_list
    related_reports = sorted(related_reports, key=lambda x: x["metadata"]["published_at"], reverse=True)
    return related_reports


st.title("ğŸ™ market octopus")
st.markdown("""
ì§ˆë¬¸ ë²”ìœ„ë¥¼ ì„ íƒí•œ ë‹¤ìŒ, ì§ˆë¬¸ì„ ì…ë ¥í•©ë‹ˆë‹¤.   
ìµœì‹  ë‰´ìŠ¤ ë° ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ ì €ì˜ ì§ˆë¬¸ì— ë‹µí•´ì¤ë‹ˆë‹¤.
""".strip())
auto_complete = draw_auto_complete()
example_ai_role = "ë‹¹ì‹ ì€ ì „ë¬¸ ì¦ê¶Œ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤."
with st.form("form"):
    system_message = example_ai_role
    instruct = st.text_area(label="ë‹µë³€ ìƒì„±ì‹œ ê³ ë ¤ì‚¬í•­", value=news_instruction, height=200)
    col1, col2 = st.columns([0.15, 0.85])
    with col1:
        question_range = st.selectbox(label="ì§ˆë¬¸ ë²”ìœ„", options=["ì „ì²´", "êµ­ë‚´", "í•´ì™¸"])
    with col2:
        question = st.text_input(
            "ì§ˆë¬¸",
            placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”",
            value=get_question(auto_complete)
        )
    submit = st.form_submit_button(label="ì œì¶œ")

if submit:
    if not question:
        st.error("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    with st.spinner("ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘..."):
        eng_question = translate([question])[0]
        eng_query = extract_query(eng_question)
        kor_query = translate([eng_query], kor_to_eng=False)[0]
        kor_question_embedding, eng_question_embedding = get_embedding([question, eng_question])
    related_news = search_related_news(
        question_range,
        kor_query,
        kor_question_embedding,
        eng_query,
        eng_question_embedding
    )
    draw_news(related_news, expanded=False)
    prompt = generate_prompt(instruct, question, related_news)
    messages = [
        {"role": "system", "content": system_message},
        {"role": "user", "content": prompt},
    ]
    streaming_response = get_streaming_response(messages)
    generated_answer = read_stream(streaming_response)
    answer_dict = {
        "related_news": related_news,
        "news_based_answer": generated_answer,
        "report_based_answer": []
    }
    # í•µì‹¬ ì•„ì´ë””ì–´ 3ê°œ ì¶”ì¶œ
    with st.spinner("í•µì‹¬ ì•„ì´ë””ì–´ ì •ë¦¬ ì¤‘..."):
        main_ideas = generate_main_ideas(question, generated_answer)
        eng_main_ideas = translate(main_ideas)
    st.markdown("**ğŸ’¡ í•µì‹¬ ì•„ì´ë””ì–´**")
    for i, main_idea in enumerate(main_ideas):
        st.write(f"{i+1}. {main_idea}")

    # í•µì‹¬ ì•„ì´ë””ì–´ì— ëŒ€í•œ ì• ë„ë¦¬í‹±ìŠ¤ ë¦¬í¬íŠ¸ ê²€ìƒ‰
    title_main_idea_list = [f"question: {eng_question}  \nmain idea: {x}" for x in eng_main_ideas]
    title_main_idea_embeddings = get_embedding(title_main_idea_list)
    visited_report = set()
    for i, (title_main_idea, title_main_idea_embedding) in enumerate(zip(title_main_idea_list, title_main_idea_embeddings)):
        related_reports = search_related_reports(question_range, title_main_idea_embedding)
        selected_report = None
        for related_report in related_reports:
            if related_report["id"] in visited_report:
                continue
            visited_report.add(related_report["id"])
            selected_report = [related_report]
            break
        if not selected_report:
            continue
        draw_related_report(selected_report, expanded=False)
        streaming_response = generate_advanced_analytics(title_main_idea, selected_report)
        report_based_answer = read_stream(streaming_response)
        generated_answer += f"\n\n{report_based_answer}"
        answer_dict["report_based_answer"].append({
            "main_idea": main_ideas[i],
            "related_reports": selected_report,
            "report_based_answer": report_based_answer
        })

    with st.spinner("ì¢…í•© ì •ë¦¬ ì¤‘..."):
        streaming_response = generate_conclusion(question, generated_answer)
    st.markdown("**ê²°ë¡ **")
    conclusion = read_stream(streaming_response)
    generated_answer += f"\n\n{conclusion}"

    with st.spinner("ë‹¤ìŒì— ë¬¼ì–´ë³´ë©´ ì¢‹ì„ ì§ˆë¬¸ë“¤..."):
        next_questions = generate_next_questions(question, generated_answer)
    draw_next_questions(next_questions)
    answer_dict["next_questions"] = next_questions
    insert_question_answer(question, answer_dict)
