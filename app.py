from datetime import datetime
from typing import List

import streamlit as st
from st_pages import show_pages_from_config

from services.service_google import translate
from services.service_openai import get_embedding, get_streaming_response, generate_next_questions, classify_intent
from services.service_pinecone import search_seeking_alpha_summary, search_seeking_alpha_content
from services.service_yfinance import draw_ticker_information
from services.streamlit_util import read_stream, default_instruction, write_common_style, \
    draw_seeking_alpha_report, set_page_config, draw_next_questions, draw_auto_complete, get_question, \
    write_common_session_state, draw_intent

set_page_config()
show_pages_from_config()
write_common_style()
write_common_session_state()


def generate_prompt(instruct: str, question: str, related_contents: List[dict]) -> str:
    related_contents_text = ""
    for i, content in enumerate(related_contents):
        content_metadata = content["metadata"]
        related_contents_text += f"""
title: {content_metadata["title"]}  
published_at: {content_metadata["published_at"]}  
summary: {content_metadata["summary"]}  
content: {content_metadata["content"]}  
"""
    prompt = f"""
{instruct}
--- 
today: {datetime.now().strftime("%Y-%m-%d")}  
question: {question}  
related analysis
{related_contents_text}
---
""".strip()
    return prompt


st.title("ğŸ™ seeking alpha")
st.markdown("""
ìœ ì €ì˜ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ë„ê°€ ë†’ì€ seeking-alpha ë¦¬í¬íŠ¸ ìµœëŒ€ 3í¸ì„ ì°¸ê³ í•´ì„œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.  
ì°¸ê³ í•œ ë¦¬í¬íŠ¸ê°€ íŠ¹ì • ì¢…ëª©ê³¼ ê´€ë ¨ì´ ìˆì„ ê²½ìš°, í˜„ì¬ ì£¼ê°€ ë°ì´í„°ë¥¼ ê·¸ë ¤ì¤ë‹ˆë‹¤.
""".strip())

auto_complete = draw_auto_complete()
example_ai_role = "ë‹¹ì‹ ì€ ì „ë¬¸ ì¦ê¶Œ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤."
with st.form("form"):
    col1, col2 = st.columns([0.8, 0.2])
    with col1:
        system_message = st.text_input(label="AI ì—­í• ", value=example_ai_role)
    with col2:
        num_reports = st.number_input(label="ì°¸ê³ í•  ë¦¬í¬íŠ¸ ê°œìˆ˜", min_value=1, max_value=3, value=1)
    instruct = st.text_area(label="ë‹µë³€ ìƒì„±ì‹œ ê³ ë ¤ì‚¬í•­", value=default_instruction, height=200)
    question = st.text_input(
        "ì§ˆë¬¸",
        placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”",
        value=get_question(auto_complete)
    )
    submit = st.form_submit_button(label="ì œì¶œ")


if submit:
    if not question:
        st.error("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    eng_question = translate([question])[0]
    with st.spinner("ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜ ì¤‘..."):
        primary_intent, secondary_intent = classify_intent(eng_question)
    draw_intent(primary_intent, secondary_intent)
    col1, col2 = st.columns([0.3, 0.7])
    with col1:
        with st.spinner("ê´€ë ¨ ë¦¬í¬íŠ¸ ê²€ìƒ‰ ì¤‘..."):
            question_embedding = get_embedding([eng_question])[0]

            # 1. questionê³¼ summaryì˜ ìœ ì‚¬ë„ë¥¼ êµ¬í•´ì„œ ê°€ì¥ ìœ ì‚¬í•œ ë¦¬í¬íŠ¸ë¥¼ 3ê°œ ì°¾ëŠ”ë‹¤.
            # 2. 3ê°œì˜ ë¦¬í¬íŠ¸ ì¤‘ì—ì„œ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ë„ê°€ ë†’ì€ ë‹¨ë½ì„ ì„ íƒí•œë‹¤.
            related_report_list = search_seeking_alpha_summary(question_embedding, k=5)
            if not related_report_list:
                st.markdown("ê´€ë ¨ ë¦¬í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                related_report_ids = [x["metadata"]["id"] for x in related_report_list]
                related_contents = search_seeking_alpha_content(question_embedding, related_report_ids, k=num_reports)
                draw_seeking_alpha_report(related_contents)
                draw_ticker_information(related_report_list)
    with col2:
        st.markdown("**ğŸ§ AI ì˜ê²¬**")
        with st.spinner("AI ì˜ê²¬ ìƒì„± ì¤‘..."):
            prompt = generate_prompt(instruct, question, related_contents)
            messages = [
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt},
            ]
            streaming_response = get_streaming_response(messages)
        answer = read_stream(streaming_response)
        with st.spinner("ë‹¤ìŒì— ë¬¼ì–´ë³´ë©´ ì¢‹ì„ ì§ˆë¬¸ë“¤..."):
            questions = generate_next_questions(question, answer)
        draw_next_questions(questions)
