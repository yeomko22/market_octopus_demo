from datetime import datetime
from typing import List

import streamlit as st
from st_pages import show_pages_from_config

from services.service_google import translate
from services.service_openai import get_embedding, generate_next_questions, classify_intent
from services.service_openai import get_streaming_response
from services.service_pinecone import search_fnguide
from services.streamlit_util import default_instruction, draw_fnguide_report, draw_auto_complete, write_common_style, \
    set_page_config, read_stream, draw_next_questions, write_common_session_state, get_question, draw_intent

set_page_config()
show_pages_from_config()
write_common_style()
write_common_session_state()

st.title("ğŸ™ fnguide")
st.markdown("""
ìœ ì €ì˜ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ë„ê°€ ë†’ì€ fnguide ë¦¬í¬íŠ¸ ìµœëŒ€ 3í¸ì„ ì°¸ê³ í•´ì„œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.  
""".strip())
auto_complete = draw_auto_complete()
example_ai_role = "ë‹¹ì‹ ì€ ì „ë¬¸ ì¦ê¶Œ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤."


def generate_prompt(instruct: str, question: str, related_contents: List[dict]) -> str:
    related_contents_text = ""
    for i, content in enumerate(related_contents):
        content_metadata = content["metadata"]
        related_contents_text += f"""
title: {content_metadata["title"]}  
published_at: {content_metadata["published_at"]}  
content: {content_metadata["eng_text"]}  
"""
    prompt = f"""
{instruct}
--- 
today: {datetime.now().strftime("%Y-%m-%d")}  
question: {question}  
related analysis
{related_contents_text}
---
""".strip()
    return prompt


with st.form("form"):
    col1, col2 = st.columns([0.8, 0.2])
    with col1:
        system_message = st.text_input(label="AI ì—­í• ", value=example_ai_role)
    with col2:
        num_reports = st.number_input(label="ì°¸ê³ í•  ë¦¬í¬íŠ¸ ê°œìˆ˜", min_value=1, max_value=3, value=1)
    instruct = st.text_area(label="ë‹µë³€ ìƒì„±ì‹œ ê³ ë ¤ì‚¬í•­", value=default_instruction, height=200)
    question = st.text_input(
        "ì§ˆë¬¸",
        placeholder="ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”",
        value=get_question(auto_complete)
    )
    submit = st.form_submit_button(label="ì œì¶œ")
if submit:
    if not question:
        st.error("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    eng_question = translate([question])[0]
    with st.spinner("ì§ˆë¬¸ ì˜ë„ ë¶„ë¥˜ ì¤‘..."):
        primary_intent, secondary_intent = classify_intent(eng_question)
    draw_intent(primary_intent, secondary_intent)
    col1, col2 = st.columns([0.3, 0.7])
    with col1:
        st.markdown("**ğŸ“ êµ­ë‚´ ì• ë„ë¦¬ìŠ¤íŠ¸ ë¦¬í¬íŠ¸**")
        with st.spinner("ê´€ë ¨ ë¦¬í¬íŠ¸ ê²€ìƒ‰ ì¤‘..."):
            question_embedding = get_embedding([eng_question])[0]
            related_report_list = search_fnguide(question_embedding, k=num_reports)
            if not related_report_list:
                st.markdown("ê´€ë ¨ ë¦¬í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                draw_fnguide_report(related_report_list)
    with col2:
        st.markdown("**ğŸ§ AI ì˜ê²¬**")
        with st.spinner("AI ì˜ê²¬ ìƒì„± ì¤‘..."):
            prompt = generate_prompt(instruct, eng_question, related_report_list)
            messages = [
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt},
            ]
            streaming_response = get_streaming_response(messages)
        answer = read_stream(streaming_response)
        with st.spinner("ë‹¤ìŒì— ë¬¼ì–´ë³´ë©´ ì¢‹ì„ ì§ˆë¬¸ë“¤..."):
            questions = generate_next_questions(question, answer)
        draw_next_questions(questions)
